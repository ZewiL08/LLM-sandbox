{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_gpt(input_str) :\n",
    "\n",
    "    chatgpt_sys_message = \"You are a helpful assistant that performs time series predictions. The user will provide a sequence and you will predict the remaining sequence. The sequence is represented by decimal strings separated by commas.\"\n",
    "    extra_input = \"Please continue the following sequence without producing any additional text. Do not say anything like 'the next terms in the sequence are', just return the numbers. Sequence:\\n\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "                model= \"gpt-4-vision-preview\",\n",
    "                messages=[\n",
    "                        {\"role\": \"system\", \"content\": chatgpt_sys_message},\n",
    "                        {\"role\": \"user\", \"content\": extra_input + input_str}\n",
    "                    ],\n",
    "                temperature=1.0,\n",
    "                n=2,\n",
    "            )\n",
    "\n",
    "    list_response = [choice.message.content for choice in response.choices]\n",
    "    return list_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_convert(data) :\n",
    "    final_str = \"\"\n",
    "    for elt in data :\n",
    "        str_number = str(round(elt))\n",
    "        final_str = final_str + str_number + \", \"\n",
    "    return final_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input str :  27591, 27511, 28301, 28416, 29473, 29313, 29231, 29233, 28069, 28670, 29026, 28839, 29507, 28850, 28431, 27670, 27629, 27599, 26970, 26796, 26776, 26919, 27162, 27034, 27406, 26821, 26881, 27103, 26748, 26850, 27220, 26329, 26474, 26706, 26855, 28065, 27737, 27695, 27211, 26818, 27243, 27070, 27116, 25729, 27230, 26340, 26499, 26478, 25842, 25926, 25905, 25934, 25129, 25597, 26344, 26517, 26340, 26844, 28308, 29995, 29885, 30690, 30528, 30463, 30268, 30693, 30077, 30447, 30472, 30586, 30617, 31156, 30767, 30505, 29896, 30345, 30285, 30161, 30412, 30622, 30380, 31455, 30313, 30290, 30233, 30139, 29860, 29910, 29800, 29902, 29794, 30084, 29177, 29229, 29352, 29223, 29314, 29353, 29281, 29232, 29706, 29185, 29193, 29112, 29071, 29087, 29210, 29770, 29581, 29454, 29425, 29430, 29303, 29430, 29199, 28729, 26624, 26054, 26100, 26190, 26127, 26055, 26433, 26179, 26059, 26017, 26101, 26119, 27717, 27300, 25940, 25805, 25870, 25971, 25826, 25792, 25759, 26254, 25910, 25902, 25841, 25162, 25840, 26222, 26523, 26600, 26560, 26528, 26763, 27210, 27125, 26568, 26580, 26576, 26248, 26304, 26221, 26372, 27022, 26907, 26963, 27993, 27495, 27427, 27779, 27411, 27932, 27957, 27917, 27590, 27390, 26875, 26759, 26862, 26853, 27155, 28502, 28396, 28320, 28715, 29670, 29910, 29993, 33070, 33922, 34496, 34152, 33893, 34081, 34526, 34476, 34641, \n",
      "GPT Answer :  ['34740', '34557, 34618, 34672, 34729, 34785, 34842, 34898, 34955, 35011', '34652, 34564, 34476, 34528', '34692', '34695', '34599, 34523, 34668, 34605, 34829, 34676, 34651, 34793, 34986, 34845', '34320, 34382, 34201, 34115, 33792, 33850, 33755, 33881, 33673, 34037', '34597, 34678, 34560, 34345, 34300', '34668, 35013, 34963, 35308', '34592, 34613']\n"
     ]
    }
   ],
   "source": [
    "ending_predict_date = '2023-11-01'\n",
    "ending_dates = ['2023-11-04', '2023-11-06', '2023-11-08']\n",
    "\n",
    "\n",
    "\n",
    "for input_length in [6, 12, 24, 48, 96, 192] :\n",
    "\n",
    "    ending_predict_date_num = datetime.strptime(ending_predict_date, '%Y-%m-%d')\n",
    "    new_date = ending_predict_date_num - timedelta(days=input_length)\n",
    "\n",
    "    start_date = new_date.strftime('%Y-%m-%d')\n",
    "    end_date = ending_dates[-1]\n",
    "\n",
    "    with open(f\"datasets/BTC_Daily_ohlc.csv\") as f:\n",
    "        df = pd.read_csv(f, usecols=[0, 4], parse_dates=[0])\n",
    "        mask = (df[\"date\"] >= start_date) & (df[\"date\"] <= end_date)\n",
    "        df = df.loc[mask]\n",
    "        df['close'] = df['close'].astype(float)\n",
    "        series = pd.Series(df['close'].values, index=df['date'])\n",
    "\n",
    "        splitpoint = input_length\n",
    "        train = series.iloc[:splitpoint]\n",
    "        test = series.iloc[splitpoint:]\n",
    "\n",
    "    input_str = str_convert(train.values)\n",
    "\n",
    "\n",
    "print(\"Input str : \", input_str)\n",
    "list_response = request_gpt(input_str)\n",
    "print(\"GPT Answer : \", list_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmtime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
